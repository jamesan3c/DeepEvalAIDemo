{"test_cases_lookup_map": {"{\"actual_output\": \"The cat ran up the tree.\", \"context\": null, \"expected_output\": \"The cat.\", \"hyperparameters\": null, \"input\": \"The dog chased the cat up the tree, who ran up the tree?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Correctness (GEval)", "threshold": 0.5, "success": true, "score": 1.0, "reason": "The actual output correctly identifies that the cat ran up the tree, consistent with the input statement.", "strictMode": false, "evaluationModel": "azure openai", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n    \"Vague language, or contradicting OPINIONS, are OK\"\n]"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "azure openai", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Check whether the facts in 'actual output' contradicts any facts in 'expected output'", "Vague language, or contradicting OPINIONS, are OK"], "evaluation_params": ["input", "actual_output"]}}, {"metric_data": {"name": "Non-vagueness (GEval)", "threshold": 0.5, "success": true, "score": 0.8, "reason": "The explanation accurately identifies the cat as the one who ran up the tree, though it could be more detailed.", "strictMode": false, "evaluationModel": "azure openai", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is vague and unclear based on the expected output \n \nEvaluation Steps:\n[\n    \"You should also heavily penalize omission of detail\",\n    \"Vague language, or contradicting OPINIONS, are NOT OK\"\n]"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "azure openai", "strict_mode": false, "criteria": "Determine whether the actual output is vague and unclear based on the expected output", "include_reason": false, "evaluation_steps": ["You should also heavily penalize omission of detail", "Vague language, or contradicting OPINIONS, are NOT OK"], "evaluation_params": ["input", "actual_output"]}}]}, "{\"actual_output\": \"It depends, some might consider the cat, while others might argue the dog. But ultimately the cat is the answer\", \"context\": null, \"expected_output\": \"The cat.\", \"hyperparameters\": null, \"input\": \"The dog chased the cat up the tree, who ran up the tree?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Correctness (GEval)", "threshold": 0.5, "success": true, "score": 0.8, "reason": "The actual output indirectly confirms that the cat ran up the tree, which aligns with the expected output. However, it introduces unnecessary ambiguity by mentioning different perspectives.", "strictMode": false, "evaluationModel": "azure openai", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n    \"Vague language, or contradicting OPINIONS, are OK\"\n]"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "azure openai", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Check whether the facts in 'actual output' contradicts any facts in 'expected output'", "Vague language, or contradicting OPINIONS, are OK"], "evaluation_params": ["input", "actual_output"]}}, {"metric_data": {"name": "Non-vagueness (GEval)", "threshold": 0.5, "success": false, "score": 0.2, "reason": "The answer is vague and contradictory, mentioning both the cat and the dog. Ultimately it does identify the cat, but the initial ambiguity and opinion-based language are significant issues.", "strictMode": false, "evaluationModel": "azure openai", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is vague and unclear based on the expected output \n \nEvaluation Steps:\n[\n    \"You should also heavily penalize omission of detail\",\n    \"Vague language, or contradicting OPINIONS, are NOT OK\"\n]"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "azure openai", "strict_mode": false, "criteria": "Determine whether the actual output is vague and unclear based on the expected output", "include_reason": false, "evaluation_steps": ["You should also heavily penalize omission of detail", "Vague language, or contradicting OPINIONS, are NOT OK"], "evaluation_params": ["input", "actual_output"]}}]}}}